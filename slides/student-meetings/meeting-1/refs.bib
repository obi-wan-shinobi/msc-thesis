@inproceedings{jacot2018ntk,
  title         = {Neural tangent kernel: Convergence and generalization in neural networks},
  author        = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2018}
}
@inproceedings{lee2019wide,
  title         = {Wide neural networks of any depth evolve as linear models under gradient descent},
  author        = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2019}
}
@inproceedings{arora2019ntk,
  title         = {On exact computation with an infinitely wide neural net},
  author        = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2019}
}
@phdthesis{neal1996priors,
  title         = {Priors for infinite networks},
  author        = {Neal, Radford M.},
  year          = {1996},
  school        = {University of Toronto}
}
@inproceedings{bai2020beyond,
  title         = {Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks},
  author        = {Bai, Yu and Lee, Jason D.},
  booktitle     = {International Conference on Learning Representations},
  year          = {2020}
}
@article{zhang2024beyondntk,
  title         = {Towards a Statistical Understanding of Neural Networks: Beyond the Neural Tangent Kernel Theories},
  author        = {Zhang, Haobo and Lai, Jianfa and Li, Yicheng and Lin, Qian and Liu, Jun S.},
  journal       = {arXiv preprint arXiv:2412.18756},
  year          = {2024}
}
